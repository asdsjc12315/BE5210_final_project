{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "Drive = drive.mount('/content/drive')\n",
        "\n",
        "print(\"Connected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm6wxU2WsFum",
        "outputId": "58ea9fc1-1baa-4984-f5bf-2bda9865793f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy import signal\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy.ndimage import gaussian_filter1d\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtFYp4LkjMru",
        "outputId": "fc43e570-8725-43cd-f219-55c8934e8582"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(ecog, glove, noise_std=0.1, time_shift=5):\n",
        "    # Add Gaussian noise\n",
        "    noisy_ecog = ecog + np.random.normal(0, noise_std, ecog.shape)\n",
        "\n",
        "    # Time shift\n",
        "    shift = np.random.randint(-time_shift, time_shift)\n",
        "    if shift > 0:\n",
        "        shifted_ecog = np.vstack([ecog[:shift], ecog[:-shift]])\n",
        "        shifted_glove = np.vstack([glove[:shift], glove[:-shift]])\n",
        "    elif shift < 0:\n",
        "        shifted_ecog = np.vstack([ecog[-shift:], ecog[:shift]]).copy()  # Create a copy here\n",
        "        shifted_glove = np.vstack([glove[-shift:], glove[:shift]]).copy()  # Create a copy here\n",
        "    else:\n",
        "        shifted_ecog = ecog.copy()\n",
        "        shifted_glove = glove.copy()\n",
        "\n",
        "    return noisy_ecog, shifted_ecog, shifted_glove"
      ],
      "metadata": {
        "id": "jW1gvCXqlElq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModel:\n",
        "    def __init__(self, n_models=5):\n",
        "        self.models = [HybridECoGModel() for _ in range(n_models)]\n",
        "\n",
        "    def train(self, ecog, glove):\n",
        "        for i, model in enumerate(self.models):\n",
        "            print(f\"Training model {i+1}/{len(self.models)}\")\n",
        "            model.train(ecog, glove)\n",
        "\n",
        "    def predict(self, ecog):\n",
        "        predictions = []\n",
        "        for model in self.models:\n",
        "            pred = model.predict(ecog)\n",
        "            predictions.append(pred)\n",
        "        return np.mean(predictions, axis=0)"
      ],
      "metadata": {
        "id": "oB34hTpulHMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Transformer Model Definition ==========\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, d_model=256, nhead=8, num_layers=3, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, d_model*4, dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.decoder = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, src):\n",
        "        src = self.encoder(src) * np.sqrt(src.shape[-1])\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "VLBI5NUelKSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Gaussian Smoothing (All points) ==========\n",
        "def gaussian_smoothing(pred, sigma=2.25):\n",
        "    pred_smooth = pred.copy()\n",
        "    for i in range(pred.shape[1]):\n",
        "        pred_smooth[:, i] = gaussian_filter1d(pred[:, i], sigma=sigma)\n",
        "    return pred_smooth\n",
        "\n",
        "# ========== Outlier Suppression (Set to 0) ==========\n",
        "def suppress_low_outliers(pred, threshold_multiplier=2):\n",
        "    pred_cleaned = pred.copy()\n",
        "    for i in range(pred.shape[1]):\n",
        "        col = pred[:, i]\n",
        "        mean = np.mean(col)\n",
        "        std = np.std(col)\n",
        "        threshold = mean - threshold_multiplier * std\n",
        "        pred_cleaned[:, i] = np.where(col < threshold, 0, col)\n",
        "    return pred_cleaned\n",
        "\n",
        "# ========== Bandpass Filter ==========\n",
        "def bandpass_filter(data, fs, lowcut, highcut, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = signal.butter(order, [low, high], btype='band')\n",
        "    return signal.filtfilt(b, a, data, axis=0)\n",
        "\n",
        "# ========== Feature Extraction ==========\n",
        "def get_features(window, fs=1000):\n",
        "    freq_bands = [(5, 15), (20, 25), (75, 115), (125, 160), (160, 175)]\n",
        "    n_channels = window.shape[1]\n",
        "    features = np.zeros((n_channels, 6))\n",
        "    features[:, 0] = np.mean(window, axis=0)\n",
        "    for i, (low, high) in enumerate(freq_bands):\n",
        "        band_filtered = bandpass_filter(window, fs, low, high)\n",
        "        features[:, i + 1] = np.mean(np.abs(band_filtered), axis=0)\n",
        "    return features\n",
        "\n",
        "# ========== Sliding Window ==========\n",
        "def get_windowed_feats(ecog, fs, win_len, overlap):\n",
        "    step = win_len - overlap\n",
        "    num_windows = (ecog.shape[0] - overlap) // step\n",
        "    feats = []\n",
        "    for i in tqdm(range(num_windows), desc=\"Extracting features\"):\n",
        "        start = i * step\n",
        "        end = start + win_len\n",
        "        if end > ecog.shape[0]:\n",
        "            break\n",
        "        window = ecog[start:end, :]\n",
        "        feats.append(get_features(window, fs).flatten())\n",
        "    return np.array(feats)\n",
        "\n",
        "# ========== Create R Matrix ==========\n",
        "def create_R_matrix(features, N_wind):\n",
        "    num_windows, num_feats = features.shape\n",
        "    pad = np.tile(features[0], (N_wind - 1, 1))\n",
        "    padded = np.vstack([pad, features])\n",
        "    R = np.zeros((num_windows, 1 + N_wind * num_feats))\n",
        "    for i in range(num_windows):\n",
        "        context = padded[i:i + N_wind].flatten()\n",
        "        R[i] = np.concatenate(([1], context))\n",
        "    return R"
      ],
      "metadata": {
        "id": "J0gLn1ZMlNxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Hybrid Model ==========\n",
        "class HybridECoGModel:\n",
        "    def __init__(self, fs=1000, window_len=100, overlap=50, N_wind=3, n_splits=5):\n",
        "        self.fs = fs\n",
        "        self.window_len = window_len\n",
        "        self.overlap = overlap\n",
        "        self.step = window_len - overlap\n",
        "        self.N_wind = N_wind\n",
        "        self.n_splits = n_splits\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "\n",
        "    # Keep your existing feature extraction methods\n",
        "    def bandpass_filter(self, data, lowcut, highcut, order=4):\n",
        "        nyq = 0.5 * self.fs\n",
        "        low = lowcut / nyq\n",
        "        high = highcut / nyq\n",
        "        b, a = signal.butter(order, [low, high], btype='band')\n",
        "        return signal.filtfilt(b, a, data, axis=0)\n",
        "\n",
        "    def get_features(self, window):\n",
        "        freq_bands = [(5, 15), (20, 25), (75, 115), (125, 160), (160, 175)]\n",
        "        n_channels = window.shape[1]\n",
        "        features = np.zeros((n_channels, 6))\n",
        "        features[:, 0] = np.mean(window, axis=0)\n",
        "        for i, (low, high) in enumerate(freq_bands):\n",
        "            band_filtered = self.bandpass_filter(window, low, high)\n",
        "            features[:, i + 1] = np.mean(np.abs(band_filtered), axis=0)\n",
        "        return features\n",
        "\n",
        "    def get_windowed_feats(self, ecog):\n",
        "        num_windows = (ecog.shape[0] - self.overlap) // self.step\n",
        "        feats = []\n",
        "        for i in range(num_windows):\n",
        "            start = i * self.step\n",
        "            end = start + self.window_len\n",
        "            if end > ecog.shape[0]:\n",
        "                break\n",
        "            window = ecog[start:end, :]\n",
        "            feats.append(self.get_features(window).flatten())\n",
        "        return np.array(feats)\n",
        "\n",
        "    def create_R_matrix(self, features):\n",
        "        num_windows, num_feats = features.shape\n",
        "        pad = np.tile(features[0], (self.N_wind - 1, 1))\n",
        "        padded = np.vstack([pad, features])\n",
        "        R = np.zeros((num_windows, 1 + self.N_wind * num_feats))\n",
        "        for i in range(num_windows):\n",
        "            context = padded[i:i + self.N_wind].flatten()\n",
        "            R[i] = np.concatenate(([1], context))\n",
        "        return R\n",
        "\n",
        "    def train(self, ecog, glove):\n",
        "        # Feature extraction\n",
        "        feats = self.get_windowed_feats(ecog)\n",
        "        R = self.create_R_matrix(feats)\n",
        "\n",
        "        # Downsample glove data\n",
        "        #glove_down = signal.decimate(glove, glove.shape[0] // R.shape[0], axis=0, zero_phase=True)[:R.shape[0]]\n",
        "        glove_down = signal.decimate(glove, glove.shape[0] // R.shape[0], axis=0, zero_phase=True)[:R.shape[0]].copy() #copy here\n",
        "\n",
        "        # Smooth glove data\n",
        "        for i in range(glove_down.shape[1]):\n",
        "            glove_down[:, i] = gaussian_filter1d(glove_down[:, i], sigma=2.25)\n",
        "\n",
        "        # Prepare data for transformer\n",
        "        X = R[:, 1:]  # Remove bias term\n",
        "        y = glove_down\n",
        "\n",
        "        # Normalize\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_tensor = torch.FloatTensor(X).unsqueeze(1).to(device)  # Add sequence dimension\n",
        "        y_tensor = torch.FloatTensor(y).to(device)\n",
        "\n",
        "        # Initialize transformer\n",
        "        input_dim = X.shape[1]\n",
        "        output_dim = y.shape[1]\n",
        "        self.model = TransformerModel(input_dim, output_dim).to(device)\n",
        "\n",
        "        # Training setup\n",
        "        criterion = nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "        # Training loop\n",
        "        n_epochs = 100\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = criterion(outputs.squeeze(1), batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            scheduler.step(epoch_loss)\n",
        "\n",
        "            if epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.4f}')\n",
        "    def predict(self, ecog, batch_size=32):  # Add batch_size argument\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet\")\n",
        "\n",
        "        # Load best model\n",
        "        self.model.load_state_dict(torch.load('best_model.pth'))\n",
        "        self.model.eval()\n",
        "\n",
        "        # Feature extraction\n",
        "        feats = self.get_windowed_feats(ecog)\n",
        "        R = self.create_R_matrix(feats)\n",
        "        X = R[:, 1:]\n",
        "        X = self.scaler.transform(X)\n",
        "\n",
        "        # Split data into batches\n",
        "        num_batches = int(np.ceil(X.shape[0] / batch_size))\n",
        "        predictions = []\n",
        "\n",
        "        for i in range(num_batches):\n",
        "            start = i * batch_size\n",
        "            end = min(start + batch_size, X.shape[0])\n",
        "            X_batch = X[start:end]\n",
        "\n",
        "            # Convert to PyTorch tensors and add sequence dimension\n",
        "            X_tensor = torch.FloatTensor(X_batch).unsqueeze(1).to(device)\n",
        "\n",
        "            # Make predictions for the batch\n",
        "            with torch.no_grad():\n",
        "                batch_predictions = self.model(X_tensor)\n",
        "\n",
        "            # Append batch predictions to the overall predictions\n",
        "            # Ensure all tensors are squeezed to the same dimensions before appending:\n",
        "            predictions.append(batch_predictions.squeeze(1).cpu().numpy())\n",
        "\n",
        "        # Concatenate batch predictions and return\n",
        "        # Explicitly pad the predictions to ensure they have the same shape before concatenation.\n",
        "        max_len = max(pred.shape[0] if pred.ndim > 0 else 0 for pred in predictions) #Check if 1D, if so, default to 0 #FIXED: changed ndim > 1 to ndim > 0 and default to 0\n",
        "        padded_predictions = []\n",
        "        for pred in predictions:\n",
        "            if pred.ndim == 2 and pred.size > 0:  # Check for 2D and non-empty\n",
        "                pad_width = ((0, max_len - pred.shape[0]), (0, 0))\n",
        "            elif pred.ndim == 1 and pred.size > 0: # Check for 1D and non-empty\n",
        "                pad_width = (0, max_len - pred.shape[0])\n",
        "            else:\n",
        "            # Handle cases where pred is empty or has unexpected dimensions\n",
        "            # You might want to raise an exception or fill with zeros\n",
        "                pad_width = (0, max_len) if max_len > 0 else (0, 0)  # Pad to max_len or leave as is if max_len is 0\n",
        "\n",
        "        padded_predictions.append(np.pad(pred, pad_width, 'constant'))\n",
        "\n",
        "        return np.vstack(padded_predictions)"
      ],
      "metadata": {
        "id": "rpPc6ypAlUAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Main Execution ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    train_data = scipy.io.loadmat('/content/drive/MyDrive/raw_training_data.mat')\n",
        "    test_data = scipy.io.loadmat('/content/drive/MyDrive/leaderboard_data.mat')\n",
        "    train_ecogs = train_data['train_ecog']\n",
        "    train_gloves = train_data['train_dg']\n",
        "    leaderboard_ecogs = test_data['leaderboard_ecog']\n",
        "\n",
        "    # Initialize model\n",
        "    model = HybridECoGModel()\n",
        "\n",
        "    # Train and predict for each subject\n",
        "    predicted_dg = np.empty((3, 1), dtype=object)\n",
        "\n",
        "    for subj_idx in range(3):\n",
        "        print(f\"\\n=== Processing Subject {subj_idx + 1} ===\")\n",
        "        ecog_train = train_ecogs[subj_idx].item()\n",
        "        glove_train = train_gloves[subj_idx].item()\n",
        "        ecog_test = leaderboard_ecogs[subj_idx].item()\n",
        "\n",
        "        # Train model\n",
        "        print(\"Training model...\")\n",
        "        model.train(ecog_train, glove_train)\n",
        "\n",
        "        # Make predictions\n",
        "        print(\"Making predictions...\")\n",
        "        #pred = model.predict(ecog_test)\n",
        "        print(\"Making predictions...\")\n",
        "        pred = model.predict(ecog_test, batch_size=32)  # Specify batch size\n",
        "\n",
        "        # Reshape predictions to 2D if necessary before padding\n",
        "        if pred.ndim > 2:\n",
        "            pred = pred.reshape(pred.shape[0], -1) # Reshape to 2D\n",
        "\n",
        "        # Ensure predictions have the correct shape\n",
        "        if pred.shape[0] < 147500:\n",
        "            padding_size = 147500 - pred.shape[0]\n",
        "            padding = np.zeros((padding_size, pred.shape[1]))\n",
        "            pred = np.concatenate((pred, padding))\n",
        "        elif pred.shape[0] > 147500:\n",
        "            pred = pred[:147500, :]\n",
        "\n",
        "        # Reshape to 147500 x 5 if necessary\n",
        "        if pred.shape[1] != 5:\n",
        "            pred = pred[:, :5]  # Truncate if more than 5 columns\n",
        "            if pred.shape[1] < 5:  # Pad if less than 5 columns\n",
        "              padding = np.zeros((pred.shape[0], 5-pred.shape[1]))\n",
        "              pred = np.concatenate((pred, padding), axis=1)\n",
        "\n",
        "        predicted_dg[subj_idx, 0] = pred\n",
        "\n",
        "    # Save predictions\n",
        "    scipy.io.savemat('enhanced_predicted_submission.mat', {'predicted_dg': predicted_dg})\n",
        "    print(\"\\n✅ Enhanced predictions saved to 'enhanced_predicted_submission.mat'\")"
      ],
      "metadata": {
        "id": "BcxHnsr5lUwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN"
      ],
      "metadata": {
        "id": "LNVkwlrGnUs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== CNN Model Definition ==========\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dims=[256, 128, 64], kernel_sizes=[5, 3, 3]):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_channels = 1  # Treat features as channels for 1D conv\n",
        "\n",
        "        for i, (h_dim, k_size) in enumerate(zip(hidden_dims, kernel_sizes)):\n",
        "            layers.extend([\n",
        "                nn.Conv1d(in_channels, h_dim, kernel_size=k_size, padding=k_size//2),\n",
        "                nn.BatchNorm1d(h_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool1d(2)\n",
        "            ])\n",
        "            in_channels = h_dim\n",
        "\n",
        "        self.cnn = nn.Sequential(*layers)\n",
        "\n",
        "        # Calculate flattened size after convolutions\n",
        "        self.flattened_size = self._get_flattened_size(input_dim, hidden_dims, kernel_sizes)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.flattened_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "\n",
        "    def _get_flattened_size(self, input_dim, hidden_dims, kernel_sizes):\n",
        "        # Simulate forward pass to get flattened size\n",
        "        x = torch.zeros(1, 1, input_dim)  # (batch, channels, length)\n",
        "        for h_dim, k_size in zip(hidden_dims, kernel_sizes):\n",
        "            x = nn.Conv1d(x.shape[1], h_dim, k_size, padding=k_size//2)(x)\n",
        "            x = nn.MaxPool1d(2)(x)\n",
        "        return x.shape[1] * x.shape[2]\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape: (batch, seq_len, features) -> reshape for CNN\n",
        "        if x.dim() == 3:\n",
        "            x = x.permute(0, 2, 1)  # (batch, features, seq_len)\n",
        "        elif x.dim() == 2:\n",
        "            x = x.unsqueeze(1)  # (batch, 1, features)\n",
        "\n",
        "        x = self.cnn(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        return self.fc(x)\n"
      ],
      "metadata": {
        "id": "KdKCUGVznTa_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Correlation Loss ==========\n",
        "class CorrelationLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, preds, targets):\n",
        "        # Input shapes: (batch, features)\n",
        "        preds = preds - preds.mean(dim=0)\n",
        "        targets = targets - targets.mean(dim=0)\n",
        "\n",
        "        cov = (preds * targets).mean(dim=0)\n",
        "        pred_std = torch.sqrt((preds**2).mean(dim=0))\n",
        "        target_std = torch.sqrt((targets**2).mean(dim=0))\n",
        "\n",
        "        corr = cov / (pred_std * target_std + 1e-8)\n",
        "        return -corr.mean()  # Negative because we want to maximize correlation\n",
        "\n",
        "# ========== Hybrid Model ==========\n",
        "class HybridECoGModel:\n",
        "    def __init__(self, fs=1000, window_len=100, overlap=50, N_wind=3, n_splits=5):\n",
        "        self.fs = fs\n",
        "        self.window_len = window_len\n",
        "        self.overlap = overlap\n",
        "        self.step = window_len - overlap\n",
        "        self.N_wind = N_wind\n",
        "        self.n_splits = n_splits\n",
        "        self.scaler = StandardScaler()\n",
        "        self.model = None\n",
        "        self.criterion = CorrelationLoss()\n",
        "\n",
        "    def bandpass_filter(self, data, lowcut, highcut, order=4):\n",
        "        nyq = 0.5 * self.fs\n",
        "        low = lowcut / nyq\n",
        "        high = highcut / nyq\n",
        "        b, a = signal.butter(order, [low, high], btype='band')\n",
        "        return signal.filtfilt(b, a, data, axis=0)\n",
        "\n",
        "    def get_features(self, window):\n",
        "        freq_bands = [(5, 15), (20, 25), (75, 115), (125, 160), (160, 175)]\n",
        "        n_channels = window.shape[1]\n",
        "        features = np.zeros((n_channels, 6))\n",
        "        features[:, 0] = np.mean(window, axis=0)\n",
        "        for i, (low, high) in enumerate(freq_bands):\n",
        "            band_filtered = self.bandpass_filter(window, low, high)\n",
        "            features[:, i + 1] = np.mean(np.abs(band_filtered), axis=0)\n",
        "        return features\n",
        "\n",
        "    def get_windowed_feats(self, ecog):\n",
        "        num_windows = (ecog.shape[0] - self.overlap) // self.step\n",
        "        feats = []\n",
        "        for i in range(num_windows):\n",
        "            start = i * self.step\n",
        "            end = start + self.window_len\n",
        "            if end > ecog.shape[0]:\n",
        "                break\n",
        "            window = ecog[start:end, :]\n",
        "            feats.append(self.get_features(window).flatten())\n",
        "        return np.array(feats)\n",
        "\n",
        "    def create_R_matrix(self, features):\n",
        "        num_windows, num_feats = features.shape\n",
        "        pad = np.tile(features[0], (self.N_wind - 1, 1))\n",
        "        padded = np.vstack([pad, features])\n",
        "        R = np.zeros((num_windows, 1 + self.N_wind * num_feats))\n",
        "        for i in range(num_windows):\n",
        "            context = padded[i:i + self.N_wind].flatten()\n",
        "            R[i] = np.concatenate(([1], context))\n",
        "        return R\n",
        "\n",
        "    def train(self, ecog, glove):\n",
        "        # Feature extraction\n",
        "        feats = self.get_windowed_feats(ecog)\n",
        "        R = self.create_R_matrix(feats)\n",
        "\n",
        "        # Downsample glove data\n",
        "        glove_down = signal.decimate(glove, glove.shape[0] // R.shape[0], axis=0, zero_phase=True)[:R.shape[0]].copy()\n",
        "\n",
        "        # Smooth glove data\n",
        "        for i in range(glove_down.shape[1]):\n",
        "            glove_down[:, i] = gaussian_filter1d(glove_down[:, i], sigma=2.25)\n",
        "\n",
        "        # Prepare data\n",
        "        X = R[:, 1:]  # Remove bias term\n",
        "        y = glove_down\n",
        "\n",
        "        # Verify output dimensions\n",
        "        assert y.shape[1] == 5, f\"Expected glove data with 5 dimensions, got {y.shape[1]}\"\n",
        "\n",
        "        # Normalize\n",
        "        X = self.scaler.fit_transform(X)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        X_tensor = torch.FloatTensor(X).to(device)\n",
        "        y_tensor = torch.FloatTensor(y).to(device)\n",
        "\n",
        "        # Initialize model\n",
        "        input_dim = X.shape[1]\n",
        "        output_dim = y.shape[1]\n",
        "        self.model = CNNModel(input_dim, output_dim).to(device)\n",
        "\n",
        "        # Training setup\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "        # Create dataset\n",
        "        dataset = torch.utils.data.TensorDataset(X_tensor, y_tensor)\n",
        "        train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "        # Training loop\n",
        "        n_epochs = 100\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for batch_X, batch_y in train_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(batch_X)\n",
        "                loss = self.criterion(outputs, batch_y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            epoch_loss /= len(train_loader)\n",
        "            scheduler.step(epoch_loss)\n",
        "\n",
        "            if epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(self.model.state_dict(), 'best_model.pth')\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f'Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    def predict(self, ecog, batch_size=32):\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"Model not trained yet\")\n",
        "\n",
        "        # Load best model\n",
        "        self.model.load_state_dict(torch.load('best_model.pth'))\n",
        "        self.model.eval()\n",
        "\n",
        "        # Feature extraction\n",
        "        feats = self.get_windowed_feats(ecog)\n",
        "        R = self.create_R_matrix(feats)\n",
        "        X = R[:, 1:]\n",
        "        X = self.scaler.transform(X)\n",
        "\n",
        "        # Make predictions in batches\n",
        "        predictions = []\n",
        "        for i in range(0, len(X), batch_size):\n",
        "            batch = X[i:i+batch_size]\n",
        "            X_tensor = torch.FloatTensor(batch).to(device)\n",
        "            with torch.no_grad():\n",
        "                batch_pred = self.model(X_tensor)\n",
        "            predictions.append(batch_pred.cpu().numpy())\n",
        "\n",
        "        pred = np.concatenate(predictions)\n",
        "        assert pred.shape[1] == 5, \"Model should output 5 dimensions\"\n",
        "\n",
        "        # Pad to required length if needed\n",
        "        if pred.shape[0] < 147500:\n",
        "            padding = np.zeros((147500 - pred.shape[0], 5))\n",
        "            pred = np.vstack([pred, padding])\n",
        "        else:\n",
        "            pred = pred[:147500]\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "nKAOLANxnXAa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Main Execution ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    train_data = scipy.io.loadmat('/content/drive/MyDrive/raw_training_data.mat')\n",
        "    test_data = scipy.io.loadmat('/content/drive/MyDrive/leaderboard_data.mat')\n",
        "    train_ecogs = train_data['train_ecog']\n",
        "    train_gloves = train_data['train_dg']\n",
        "    leaderboard_ecogs = test_data['leaderboard_ecog']\n",
        "\n",
        "    # Initialize model\n",
        "    model = HybridECoGModel()\n",
        "\n",
        "    # Train and predict for each subject\n",
        "    predicted_dg = np.empty((3, 1), dtype=object)\n",
        "\n",
        "    for subj_idx in range(3):\n",
        "        print(f\"\\n=== Processing Subject {subj_idx + 1} ===\")\n",
        "        ecog_train = train_ecogs[subj_idx].item()\n",
        "        glove_train = train_gloves[subj_idx].item()\n",
        "        ecog_test = leaderboard_ecogs[subj_idx].item()\n",
        "\n",
        "        # Train model\n",
        "        print(\"Training model...\")\n",
        "        model.train(ecog_train, glove_train)\n",
        "\n",
        "        # Make predictions\n",
        "        print(\"Making predictions...\")\n",
        "        pred = model.predict(ecog_test, batch_size=32)\n",
        "\n",
        "        predicted_dg[subj_idx, 0] = pred\n",
        "\n",
        "    # Save predictions\n",
        "    scipy.io.savemat('enhanced_predicted_submission.mat', {'predicted_dg': predicted_dg})\n",
        "    print(\"\\n✅ Enhanced predictions saved to 'enhanced_predicted_submission.mat'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o74vnMAondLv",
        "outputId": "4bfe7e72-2c7b-4d2c-cc3d-975f2420b36b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "=== Processing Subject 1 ===\n",
            "Training model...\n",
            "Epoch 10/100, Loss: -0.9466\n",
            "Epoch 20/100, Loss: -0.9561\n",
            "Epoch 30/100, Loss: -0.9809\n",
            "Epoch 40/100, Loss: -0.9842\n",
            "Epoch 50/100, Loss: -0.9850\n",
            "Epoch 60/100, Loss: -0.9979\n",
            "Epoch 70/100, Loss: -0.9992\n",
            "Epoch 80/100, Loss: -0.9994\n",
            "Epoch 90/100, Loss: -0.9995\n",
            "Epoch 100/100, Loss: -0.9996\n",
            "Making predictions...\n",
            "\n",
            "=== Processing Subject 2 ===\n",
            "Training model...\n",
            "Epoch 10/100, Loss: -0.9270\n",
            "Epoch 20/100, Loss: -0.9660\n",
            "Epoch 30/100, Loss: -0.9813\n",
            "Epoch 40/100, Loss: -0.9926\n",
            "Epoch 50/100, Loss: -0.9977\n",
            "Epoch 60/100, Loss: -0.9987\n",
            "Epoch 70/100, Loss: -0.9990\n",
            "Epoch 80/100, Loss: -0.9991\n",
            "Epoch 90/100, Loss: -0.9991\n",
            "Epoch 100/100, Loss: -0.9991\n",
            "Making predictions...\n",
            "\n",
            "=== Processing Subject 3 ===\n",
            "Training model...\n",
            "Epoch 10/100, Loss: -0.9611\n",
            "Epoch 20/100, Loss: -0.9786\n",
            "Epoch 30/100, Loss: -0.9783\n",
            "Epoch 40/100, Loss: -0.9851\n",
            "Epoch 50/100, Loss: -0.9964\n",
            "Epoch 60/100, Loss: -0.9989\n",
            "Epoch 70/100, Loss: -0.9995\n",
            "Epoch 80/100, Loss: -0.9995\n",
            "Epoch 90/100, Loss: -0.9995\n",
            "Epoch 100/100, Loss: -0.9995\n",
            "Making predictions...\n",
            "\n",
            "✅ Enhanced predictions saved to 'enhanced_predicted_submission.mat'\n"
          ]
        }
      ]
    }
  ]
}