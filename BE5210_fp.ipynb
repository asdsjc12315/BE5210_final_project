{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from google.colab import drive\n",
        "Drive = drive.mount('/content/drive')\n",
        "\n",
        "print(\"Connected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv6tAlAlpAFL",
        "outputId": "5717a67d-d5da-4660-bdb3-f15045f4f86f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy import signal, interpolate\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# ========== Parameters ==========\n",
        "fs = 1000                      # Sampling frequency (Hz)\n",
        "window_len = 200               # Window length increased to 200ms\n",
        "overlap = 100                  # 50% overlap (100ms)\n",
        "step = window_len - overlap    # Step size between windows\n",
        "N_wind = 6                     # Number of historical windows (300ms context)\n",
        "delay_steps = 2                # 100ms delay compensation (2 steps × 50ms/step)\n",
        "\n",
        "# ========== Filtering Function ==========\n",
        "def filter_data(raw_eeg, fs=1000):\n",
        "    \"\"\"Bandpass filter (1-180Hz) using FIR filter\"\"\"\n",
        "    b = signal.firwin(101, [1, 180], pass_zero='bandpass', fs=fs)\n",
        "    return signal.lfilter(b, [1.0], raw_eeg, axis=0)\n",
        "\n",
        "# ========== Enhanced Feature Extraction ==========\n",
        "def get_features(filtered_window, fs=1000):\n",
        "    \"\"\"Extract time-domain and frequency-domain features\"\"\"\n",
        "    num_samples, num_channels = filtered_window.shape\n",
        "\n",
        "    # Time-domain features\n",
        "    time_feats = np.array([\n",
        "        np.var(filtered_window, axis=0),                      # Variance\n",
        "        ((filtered_window[:-1] * filtered_window[1:]) < 0).sum(axis=0) / num_samples  # Zero-crossing rate\n",
        "    ])\n",
        "\n",
        "    # Frequency-domain features (focus on motor-related bands)\n",
        "    freq_bands = [(13, 30), (70, 200)]  # β and γ bands\n",
        "    freqs = np.fft.rfftfreq(num_samples, d=1/fs)\n",
        "    fft_vals = np.abs(np.fft.rfft(filtered_window, axis=0))\n",
        "\n",
        "    features = []\n",
        "    for ch in range(num_channels):\n",
        "        # Band energy calculations with empty band check\n",
        "        band_energy = [np.mean(fft_vals[(freqs >= low) & (freqs < high), ch])\n",
        "                      if np.any((freqs >= low) & (freqs < high)) else 0\n",
        "                      for low, high in freq_bands]\n",
        "\n",
        "        features.append(np.concatenate([\n",
        "            time_feats[:, ch],\n",
        "            band_energy,\n",
        "            [band_energy[1] / (band_energy[0] + 1e-10)]  # γ/β ratio\n",
        "        ]))\n",
        "\n",
        "    return np.array(features)\n",
        "\n",
        "# ========== Time-Delayed R Matrix Construction ==========\n",
        "def create_R_matrix(features, N_wind, delay=0):\n",
        "    \"\"\"Create design matrix with delay compensation\"\"\"\n",
        "    padded = np.vstack([np.tile(features[0], (N_wind + delay - 1, 1)), features])\n",
        "    R = np.zeros((len(features), 1 + N_wind * features.shape[1]))\n",
        "    for i in range(len(features)):\n",
        "        window_feats = padded[i + delay : i + delay + N_wind].flatten()\n",
        "        R[i] = np.concatenate(([1], window_feats))  # Add bias term\n",
        "    return R\n",
        "\n",
        "# ========== Downsampling & Interpolation ==========\n",
        "def downsample_glove(glove, window_len, overlap):\n",
        "    \"\"\"Downsample glove data to match feature rate\"\"\"\n",
        "    return np.array([\n",
        "        np.mean(glove[i*step : i*step + window_len], axis=0)\n",
        "        for i in range((len(glove) - overlap) // step)\n",
        "    ])\n",
        "\n",
        "def interpolate_prediction(pred, original_len, step):\n",
        "    \"\"\"Upsample predictions from 50Hz to 1000Hz\"\"\"\n",
        "    x_old = np.arange(pred.shape[0]) * step\n",
        "    x_new = np.arange(original_len)\n",
        "    return np.column_stack([\n",
        "        interpolate.CubicSpline(x_old, pred[:, i])(x_new)\n",
        "        for i in range(pred.shape[1])\n",
        "    ])\n",
        "\n",
        "# ========== Sliding Window Features ==========\n",
        "'''\n",
        "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap, disable_tqdm=False):\n",
        "    num_samples, num_channels = raw_ecog.shape\n",
        "    step = window_length - window_overlap\n",
        "    num_windows = (num_samples - window_overlap) // step\n",
        "    all_feats = []\n",
        "    for i in tqdm(range(num_windows), desc=\"Extracting features\", disable=disable_tqdm):\n",
        "        start = i * step\n",
        "        end = start + window_length\n",
        "        if end > num_samples:\n",
        "            break\n",
        "        window = raw_ecog[start:end, :]\n",
        "        filtered = filter_data(window, fs=fs)\n",
        "        feats = get_features(filtered, fs=fs)\n",
        "        all_feats.append(feats.flatten())\n",
        "    return np.array(all_feats)\n",
        "'''\n",
        "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap, disable_tqdm=False):\n",
        "    num_samples, num_channels = raw_ecog.shape\n",
        "    step = window_length - window_overlap\n",
        "    num_windows = (num_samples - window_overlap) // step\n",
        "    all_feats = []\n",
        "    for i in tqdm(range(num_windows), desc=\"Extracting features\", disable=disable_tqdm):\n",
        "        start = i * step\n",
        "        end = start + window_length\n",
        "        if end > num_samples:\n",
        "            break\n",
        "        window = raw_ecog[start:end, :]\n",
        "        filtered = filter_data(window, fs=fs)\n",
        "        feats = get_features(filtered, fs=fs)\n",
        "        all_feats.append(feats.flatten())\n",
        "    return np.array(all_feats)\n",
        "\n",
        "\n",
        "# ========== Performance Evaluation ==========\n",
        "def calculate_r2(true, pred):\n",
        "    \"\"\"Calculate R² score for each finger\"\"\"\n",
        "    ss_res = np.sum((true - pred)**2, axis=0)\n",
        "    ss_tot = np.sum((true - np.mean(true, axis=0))**2, axis=0)\n",
        "    return 1 - (ss_res / (ss_tot + 1e-10))  # Avoid division by zero\n",
        "\n",
        "# ========== Main Processing Pipeline ==========\n",
        "\n",
        "def run_subject(ecog_train, glove_train, ecog_test=None, show_progress=False):\n",
        "    \"\"\"Complete processing pipeline for one subject\"\"\"\n",
        "    # Feature extraction with optional progress bar\n",
        "    with tqdm(total=3, desc=\"Processing\", disable=not show_progress) as pbar:\n",
        "        feats_train = get_windowed_feats(ecog_train, fs, window_len, overlap, disable_tqdm=True)\n",
        "        pbar.update(1)\n",
        "\n",
        "        feats_train = StandardScaler().fit_transform(feats_train)\n",
        "        pbar.update(1)\n",
        "\n",
        "        R_train = create_R_matrix(feats_train, N_wind, delay_steps)\n",
        "        glove_down = downsample_glove(glove_train, window_len, overlap)\n",
        "        pbar.update(1)\n",
        "\n",
        "    # Ridge regression training and CV\n",
        "    model = Ridge(alpha=1.0).fit(R_train, glove_down)\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    val_r2 = []\n",
        "    for train_idx, val_idx in tscv.split(R_train):\n",
        "        val_r2.append(calculate_r2(\n",
        "            glove_down[val_idx],\n",
        "            model.predict(R_train[val_idx])\n",
        "        ))\n",
        "\n",
        "    if ecog_test is not None:\n",
        "        feats_test = get_windowed_feats(ecog_test, fs, window_len, overlap, disable_tqdm=True)\n",
        "        feats_test = StandardScaler().fit_transform(feats_test)\n",
        "        R_test = create_R_matrix(feats_test, N_wind, delay_steps)\n",
        "        pred_50hz = model.predict(R_test)\n",
        "        pred_1000hz = interpolate_prediction(pred_50hz, ecog_test.shape[0], step)\n",
        "        return pred_1000hz, np.mean(val_r2)\n",
        "\n",
        "    return None, np.mean(val_r2)\n",
        "'''\n",
        "def run_subject(ecog_train, glove_train, ecog_test=None):\n",
        "    \"\"\"Complete processing pipeline for one subject\"\"\"\n",
        "    # Feature extraction with progress bar\n",
        "    with tqdm(total=3, desc=\"Processing\") as pbar:\n",
        "        feats_train = get_windowed_feats(ecog_train, fs, window_len, overlap)\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Feature standardization\n",
        "        feats_train = StandardScaler().fit_transform(feats_train)\n",
        "        pbar.update(1)\n",
        "\n",
        "        # Create design matrix with delay compensation\n",
        "        R_train = create_R_matrix(feats_train, N_wind, delay_steps)\n",
        "        glove_down = downsample_glove(glove_train, window_len, overlap)\n",
        "        pbar.update(1)\n",
        "\n",
        "    # Ridge regression model training\n",
        "    model = Ridge(alpha=1.0).fit(R_train, glove_down)\n",
        "\n",
        "    # Time-series cross-validation\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    val_r2 = []\n",
        "    for train_idx, val_idx in tscv.split(R_train):\n",
        "        val_r2.append(calculate_r2(\n",
        "            glove_down[val_idx],\n",
        "            model.predict(R_train[val_idx])\n",
        "        ))\n",
        "\n",
        "    # Test set prediction\n",
        "    if ecog_test is not None:\n",
        "        feats_test = get_windowed_feats(ecog_test, fs, window_len, overlap)\n",
        "        feats_test = StandardScaler().fit_transform(feats_test)\n",
        "        R_test = create_R_matrix(feats_test, N_wind, delay_steps)\n",
        "        pred_50hz = model.predict(R_test)\n",
        "        pred_1000hz = interpolate_prediction(pred_50hz, ecog_test.shape[0], step)\n",
        "        return pred_1000hz, np.mean(val_r2)\n",
        "\n",
        "    return None, np.mean(val_r2)\n",
        "'''\n",
        "# ========== Main Execution ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    train_data = scipy.io.loadmat('/content/drive/MyDrive/raw_training_data.mat')\n",
        "    test_data = scipy.io.loadmat('/content/drive/MyDrive/leaderboard_data.mat')\n",
        "    train_ecogs = train_data['train_ecog']\n",
        "    train_gloves = train_data['train_dg']\n",
        "    leaderboard_ecogs = test_data['leaderboard_ecog']\n",
        "\n",
        "   # Process each subject\n",
        "    all_preds, all_r2 = {}, []\n",
        "    with tqdm(total=3, desc=\"Processing Subjects\", bar_format='{l_bar}{bar:30}{r_bar}', dynamic_ncols=True) as progress_bar:\n",
        "        for subj in range(3):\n",
        "            print(f\"\\n=== Processing Subject {subj+1} ===\")\n",
        "            pred, r2 = run_subject(\n",
        "                train_ecogs[subj].item(),\n",
        "                train_gloves[subj].item(),\n",
        "                leaderboard_ecogs[subj].item(),\n",
        "                show_progress=False\n",
        "            )\n",
        "            all_preds[f'subj_{subj+1}'] = pred\n",
        "            all_r2.append(r2)\n",
        "            print(f\"Validation R²: {r2:.3f}\")\n",
        "            progress_bar.update(1)\n",
        "\n",
        "\n",
        "    # Save results in submission format\n",
        "    predicted_dg = np.empty((3, 1), dtype=object)\n",
        "    for i in range(3):\n",
        "        predicted_dg[i, 0] = all_preds[f'subj_{i+1}']\n",
        "    scipy.io.savemat('improved_prediction.mat', {'predicted_dg': predicted_dg})\n",
        "\n",
        "    print(f\"\\nAverage R² across subjects: {np.mean(all_r2):.3f}\")\n",
        "    print(\"✅ Results saved to improved_prediction.mat\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFVvU4TpAe9",
        "outputId": "52ee64a7-b7ed-4a38-aa3c-b4350d10c990"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Subjects:   0%|                              | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing Subject 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Subjects:  33%|██████████                    | 1/3 [00:26<00:53, 26.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation R²: 0.614\n",
            "\n",
            "=== Processing Subject 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing Subjects:  67%|████████████████████          | 2/3 [00:47<00:23, 23.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation R²: 0.576\n",
            "\n",
            "=== Processing Subject 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Subjects: 100%|██████████████████████████████| 3/3 [01:13<00:00, 24.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation R²: 0.790\n",
            "\n",
            "Average R² across subjects: 0.660\n",
            "✅ Results saved to improved_prediction.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}