{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukGBAAyybL5K",
        "outputId": "b69c2433-c2f2-4322-c6ad-4677cf9932ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "=== Processing Subject 1 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 5999/5999 [00:07<00:00, 835.75it/s]\n",
            "Training: 100%|██████████| 100/100 [01:20<00:00,  1.24it/s]\n",
            "Extracting features: 100%|██████████| 2949/2949 [00:03<00:00, 905.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing Subject 2 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 5999/5999 [00:06<00:00, 921.06it/s]\n",
            "Training: 100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n",
            "Extracting features: 100%|██████████| 2949/2949 [00:02<00:00, 1119.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing Subject 3 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting features: 100%|██████████| 5999/5999 [00:06<00:00, 957.97it/s]\n",
            "Training: 100%|██████████| 100/100 [01:20<00:00,  1.25it/s]\n",
            "Extracting features: 100%|██████████| 2949/2949 [00:03<00:00, 978.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Predictions saved to transformer_prediction.mat\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "from scipy import signal, interpolate\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "# ========== Parameters ==========\n",
        "fs = 1000\n",
        "window_len = 100  # 100ms window\n",
        "overlap = 50      # 50ms overlap\n",
        "step = window_len - overlap\n",
        "delay_steps = 3   # 150ms lag (3 windows)\n",
        "\n",
        "# Frequency bands (Hz)\n",
        "freq_bands = [\n",
        "    (5, 15),    # Band 1\n",
        "    (20, 25),   # Band 2\n",
        "    (75, 115),  # Band 3\n",
        "    (125, 160), # Band 4\n",
        "    (160, 175)  # Band 5\n",
        "]\n",
        "\n",
        "# ========== GPU Setup ==========\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ========== Transformer Model ==========\n",
        "class ECoGTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=5, d_model=128, nhead=4, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        encoder_layers = TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=512,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(d_model, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, seq_len, input_dim]\n",
        "        x = self.embedding(x)  # [batch_size, seq_len, d_model]\n",
        "        x = self.transformer(x)  # [batch_size, seq_len, d_model]\n",
        "        x = x.mean(dim=1)  # Global average pooling\n",
        "        return self.fc(x)\n",
        "\n",
        "# ========== Signal Processing ==========\n",
        "def filter_data(raw_eeg, fs=1000):\n",
        "    \"\"\"Bandpass filter 1-200Hz\"\"\"\n",
        "    b = signal.firwin(101, [1, 200], pass_zero='bandpass', fs=fs)\n",
        "    return signal.lfilter(b, [1.0], raw_eeg, axis=0)\n",
        "\n",
        "def extract_window_features(window, fs=1000):\n",
        "    \"\"\"Extract 6 features per channel (1 time + 5 freq bands)\"\"\"\n",
        "    num_samples, num_channels = window.shape\n",
        "\n",
        "    # 1. Time-domain feature: average voltage\n",
        "    time_feat = np.mean(window, axis=0)  # [num_channels]\n",
        "\n",
        "    # 2. Frequency-domain features\n",
        "    freqs = np.fft.rfftfreq(num_samples, d=1/fs)\n",
        "    fft_vals = np.abs(np.fft.rfft(window, axis=0))\n",
        "\n",
        "    freq_feats = []\n",
        "    for low, high in freq_bands:\n",
        "        mask = (freqs >= low) & (freqs < high)\n",
        "        if np.any(mask):\n",
        "            band_energy = np.mean(fft_vals[mask], axis=0)  # [num_channels]\n",
        "        else:\n",
        "            band_energy = np.zeros(num_channels)\n",
        "        freq_feats.append(band_energy)\n",
        "\n",
        "    # Combine features: [num_channels, 6]\n",
        "    return np.column_stack([time_feat] + freq_feats)\n",
        "\n",
        "def get_windowed_features(raw_ecog, fs, window_len, overlap):\n",
        "    \"\"\"Extract features for all windows\"\"\"\n",
        "    num_samples, num_channels = raw_ecog.shape\n",
        "    step = window_len - overlap\n",
        "    num_windows = (num_samples - overlap) // step\n",
        "\n",
        "    all_features = []\n",
        "    for i in tqdm(range(num_windows), desc=\"Extracting features\"):\n",
        "        start = i * step\n",
        "        end = start + window_len\n",
        "        window = raw_ecog[start:end, :]\n",
        "        filtered = filter_data(window, fs=fs)\n",
        "        features = extract_window_features(filtered, fs=fs)\n",
        "        all_features.append(features.flatten())  # Flatten to [num_channels*6]\n",
        "\n",
        "    return np.array(all_features)\n",
        "\n",
        "def create_sequential_dataset(features, delay_steps):\n",
        "    \"\"\"Create input sequences with delay\"\"\"\n",
        "    seq_features = []\n",
        "    for i in range(delay_steps, len(features)):\n",
        "        seq = features[i-delay_steps:i]\n",
        "        seq_features.append(seq)\n",
        "    return np.stack(seq_features)\n",
        "\n",
        "# ========== Data Preparation ==========\n",
        "def downsample_glove(glove, window_len, overlap):\n",
        "    \"\"\"Downsample glove data to match feature rate\"\"\"\n",
        "    step = window_len - overlap\n",
        "    return np.array([\n",
        "        np.mean(glove[i*step : i*step + window_len], axis=0)\n",
        "        for i in range((len(glove) - overlap) // step)\n",
        "    ])\n",
        "\n",
        "def interpolate_prediction(pred, original_len, step):\n",
        "    \"\"\"Upsample predictions to original rate\"\"\"\n",
        "    x_old = np.arange(pred.shape[0]) * step\n",
        "    x_new = np.arange(original_len)\n",
        "    return np.column_stack([\n",
        "        interpolate.CubicSpline(x_old, pred[:, i])(x_new)\n",
        "        for i in range(pred.shape[1])\n",
        "    ])\n",
        "\n",
        "# ========== Training Pipeline ==========\n",
        "def train_transformer(X_train, y_train, device):\n",
        "    \"\"\"Train transformer model\"\"\"\n",
        "    # Convert to PyTorch tensors\n",
        "    train_x = torch.FloatTensor(X_train).to(device)  # [batch, seq_len, features]\n",
        "    train_y = torch.FloatTensor(y_train).to(device)\n",
        "    dataset = TensorDataset(train_x, train_y)\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = X_train.shape[-1]\n",
        "    model = ECoGTransformer(input_dim=input_dim).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "    # Training loop\n",
        "    train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "    best_loss = float('inf')\n",
        "    for epoch in tqdm(range(100), desc=\"Training\"):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        scheduler.step(epoch_loss)\n",
        "        if epoch_loss < best_loss:\n",
        "            best_loss = epoch_loss\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "\n",
        "    return model\n",
        "\n",
        "# ========== Main Execution ==========\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    train_data = scipy.io.loadmat('raw_training_data.mat')\n",
        "    test_data = scipy.io.loadmat('leaderboard_data.mat')\n",
        "    train_ecogs = [train_data['train_ecog'][i].item() for i in range(3)]\n",
        "    train_gloves = [train_data['train_dg'][i].item() for i in range(3)]\n",
        "    test_ecogs = [test_data['leaderboard_ecog'][i].item() for i in range(3)]\n",
        "\n",
        "    # Process each subject\n",
        "    all_preds = []\n",
        "    for subj in range(3):\n",
        "        print(f\"\\n=== Processing Subject {subj+1} ===\")\n",
        "\n",
        "        # Feature extraction\n",
        "        feats = get_windowed_features(train_ecogs[subj], fs, window_len, overlap)\n",
        "        feats = StandardScaler().fit_transform(feats)\n",
        "\n",
        "        # Create sequential dataset with delay\n",
        "        X_seq = create_sequential_dataset(feats, delay_steps)\n",
        "        glove_down = downsample_glove(train_gloves[subj], window_len, overlap)\n",
        "        y_train = glove_down[delay_steps:]  # Align with delayed features\n",
        "\n",
        "        # Train Transformer\n",
        "        model = train_transformer(X_seq, y_train, device)\n",
        "\n",
        "        # Test prediction\n",
        "        test_feats = get_windowed_features(test_ecogs[subj], fs, window_len, overlap)\n",
        "        test_feats = StandardScaler().fit_transform(test_feats)\n",
        "        X_test_seq = create_sequential_dataset(test_feats, delay_steps)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_50hz = model(torch.FloatTensor(X_test_seq).to(device)).cpu().numpy()\n",
        "\n",
        "        # Interpolate to 1000Hz\n",
        "        pred_1000hz = interpolate_prediction(\n",
        "            pred_50hz,\n",
        "            len(test_ecogs[subj]),\n",
        "            step\n",
        "        )\n",
        "        all_preds.append(pred_1000hz)\n",
        "\n",
        "    # Save results\n",
        "    predicted_dg = np.empty((3,1), dtype=object)\n",
        "    for i in range(3):\n",
        "        predicted_dg[i,0] = all_preds[i]\n",
        "    scipy.io.savemat('transformer_prediction.mat', {'predicted_dg': predicted_dg})\n",
        "    print(\"\\n✅ Predictions saved to transformer_prediction.mat\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Use same inputs as before\n",
        "n_splits = 5\n",
        "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_seq)):\n",
        "    print(f\"\\n📂 Fold {fold+1}/{n_splits}\")\n",
        "\n",
        "    # Split into train/validation\n",
        "    X_train_cv, X_val_cv = X_seq[train_idx], X_seq[val_idx]\n",
        "    y_train_cv, y_val_cv = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Train model on this fold\n",
        "    model_cv = train_transformer(X_train_cv, y_train_cv, device)\n",
        "\n",
        "    # Predict on validation set\n",
        "    with torch.no_grad():\n",
        "        val_pred = model_cv(torch.FloatTensor(X_val_cv).to(device)).cpu().numpy()\n",
        "\n",
        "    # Compute R² score\n",
        "    r2 = r2_score(y_val_cv, val_pred, multioutput='variance_weighted')\n",
        "    print(f\"Fold {fold+1} R²: {r2:.4f}\")\n",
        "    scores.append(r2)\n",
        "\n",
        "# Final cross-validation performance\n",
        "print(f\"\\n✅ Average R² across {n_splits} folds: {np.mean(scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp7V83q8dkvo",
        "outputId": "dc2a211d-70d5-4c68-9e79-eea147bf2f5b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📂 Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [01:11<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 R²: 0.9009\n",
            "\n",
            "📂 Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [01:05<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 R²: 0.8961\n",
            "\n",
            "📂 Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [01:03<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 R²: 0.8951\n",
            "\n",
            "📂 Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [01:03<00:00,  1.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 R²: 0.8898\n",
            "\n",
            "📂 Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [01:05<00:00,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 R²: 0.8955\n",
            "\n",
            "✅ Average R² across 5 folds: 0.8955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}